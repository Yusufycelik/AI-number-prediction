{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import Canvas, Button, Label, font\n",
    "from PIL import ImageGrab\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli kütüphanelerin ve modüllerin içe aktarılması: os, cv2, numpy, PIL ve tkinter kütüphaneleri içe aktarılır. Ayrıca, ekran görüntüsü almak için ImageGrab modülü içe aktarılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf sayısı\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntü boyutları\n",
    "img_width, img_height = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    class_names = os.listdir(data_dir)\n",
    "    num_classes = len(class_names)\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            label = i\n",
    "            label_encoder.fit([label])\n",
    "            \n",
    "            for filename in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, filename)\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, (img_width, img_height))\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, num_classes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setinin yüklenmesi: load_data fonksiyonu kullanılarak belirtilen veri dizininden görüntüler ve etiketler yüklenir. Veriler, images ve labels adlı numpy dizileri olarak döndürülür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Veri setini yükle\n",
    "data_dir = 'C:/Users/ysfcl\\Desktop/YapayzekaProje/binary_images'\n",
    "images, labels, num_classes = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve test veri setlerine ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setinin eğitim ve test verilerine ayrılması: train_test_split fonksiyonu kullanılarak yüklenen veri seti eğitim ve test veri setlerine ayrılır. Eğitim ve test verileri, x_train, x_test, y_train ve y_test adlı numpy dizileri olarak elde edilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train'i one-hot encoding'e dönüştürme\n",
    "y_train_encoded = to_categorical(y_train, num_classes)\n",
    "\n",
    "# y_test'i one-hot encoding'e dönüştürme\n",
    "y_test_encoded = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri önişleme: Eğitim ve test verileri normalize edilir ve etiketler one-hot encoding'e dönüştürülür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (252, 28, 28)\n",
      "y_train shape: (252,)\n",
      "x_test shape: (63, 28, 28)\n",
      "y_test shape: (63,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi train ve test olarak ayır\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi normalize etme\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verileri normalize etmek, değerlerin 0 ile 1 arasında bir ölçekte olmasını sağlar. Bu genellikle görüntü verileriyle çalışırken kullanılan bir ön işleme adımıdır.\n",
    "\n",
    "x_train ve x_test verilerini 0 ile 255 arasındaki piksel değerlerine sahip görüntüler içeriyorsa, bu kod satırları verileri 0 ile 1 arasında bir ölçekte normalleştirir. Bunu yaparak, modelin daha iyi öğrenme yapmasını ve daha iyi sonuçlar elde etmesini sağlamayı hedefledik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiketleri one-hot encoding ile dönüştürme\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli oluşturma\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin oluşturulması: Sequential modeli kullanılarak bir sinir ağı modeli oluşturulur. Model, 2D evrişimli katmanlar, pooling katmanları, tam bağlantılı katmanlar ve dropout katmanı içerir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli derleme\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin derlenmesi: Model, adam optimizeri ve categorical_crossentropy kaybı ile derlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "36/36 [==============================] - 1s 12ms/step - loss: 2.3244 - accuracy: 0.0813 - val_loss: 2.3032 - val_accuracy: 0.1562\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.2972 - accuracy: 0.1025 - val_loss: 2.2923 - val_accuracy: 0.0938\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.3127 - accuracy: 0.1237 - val_loss: 2.2904 - val_accuracy: 0.1875\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 2.2778 - accuracy: 0.1802 - val_loss: 2.2281 - val_accuracy: 0.1562\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 2.1866 - accuracy: 0.2049 - val_loss: 2.1083 - val_accuracy: 0.1562\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 2.0722 - accuracy: 0.2297 - val_loss: 1.9553 - val_accuracy: 0.5000\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.8745 - accuracy: 0.3039 - val_loss: 1.7718 - val_accuracy: 0.3750\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.7561 - accuracy: 0.3781 - val_loss: 1.6906 - val_accuracy: 0.4062\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.6293 - accuracy: 0.4417 - val_loss: 1.6226 - val_accuracy: 0.5312\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.4847 - accuracy: 0.4558 - val_loss: 1.5438 - val_accuracy: 0.4062\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.4848 - accuracy: 0.4700 - val_loss: 1.4727 - val_accuracy: 0.4062\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2844 - accuracy: 0.5724 - val_loss: 1.4802 - val_accuracy: 0.5625\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.5618 - val_loss: 1.3571 - val_accuracy: 0.5312\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1657 - accuracy: 0.5936 - val_loss: 1.3903 - val_accuracy: 0.5625\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0442 - accuracy: 0.6502 - val_loss: 1.4698 - val_accuracy: 0.4062\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0435 - accuracy: 0.6042 - val_loss: 1.3201 - val_accuracy: 0.5938\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9800 - accuracy: 0.6678 - val_loss: 1.3536 - val_accuracy: 0.5312\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9006 - accuracy: 0.6678 - val_loss: 1.3618 - val_accuracy: 0.5312\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8126 - accuracy: 0.7385 - val_loss: 1.2818 - val_accuracy: 0.5625\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8293 - accuracy: 0.7032 - val_loss: 1.3154 - val_accuracy: 0.4688\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6478 - accuracy: 0.7668 - val_loss: 1.3533 - val_accuracy: 0.5625\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.7703 - val_loss: 1.3652 - val_accuracy: 0.5312\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5685 - accuracy: 0.8233 - val_loss: 1.2589 - val_accuracy: 0.5938\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5992 - accuracy: 0.8021 - val_loss: 1.2920 - val_accuracy: 0.5312\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5711 - accuracy: 0.8163 - val_loss: 1.2328 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa6d7558a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeli eğitme\n",
    "model.fit(x_train[..., np.newaxis], y_train, epochs=25, batch_size=8, validation_data=(x_test[..., np.newaxis], y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin eğitilmesi: Model, eğitim verileriyle belirli bir epoch sayısında eğitilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step - loss: 1.2328 - accuracy: 0.5625\n",
      "Test loss: 1.2327985763549805\n",
      "Test accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "# Modeli değerlendirme\n",
    "loss, accuracy = model.evaluate(x_test[..., np.newaxis], y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin değerlendirilmesi: Model, test verileri üzerinde değerlendirilir ve kayıp değeri ile doğruluk oranı görüntülenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni bir görüntüyü tahmin etme\n",
    "def predict_new_image(image_path):\n",
    "    # Görüntüyü yükle\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Tahmin yap\n",
    "    input_image = image[np.newaxis, ..., np.newaxis]\n",
    "    prediction = model.predict(input_image)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni bir görüntünün tahmin edilmesi: predict_new_image fonksiyonu kullanılarak yeni bir görüntünün tahmini yapılır. Görüntü önceden belirtilen boyutlara yeniden boyutlandırılır, normalize edilir ve model üzerinde tahmin işlemi gerçekleştirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "Tahmin: 1\n"
     ]
    }
   ],
   "source": [
    "# Yeni bir görüntüyü tahmin etme örneği\n",
    "new_image_path = 'C:/Users/ysfcl/Desktop/YapayzekaProje/numbers/1.jpg'\n",
    "predicted_label = predict_new_image(new_image_path)\n",
    "print('Tahmin:', predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
